# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ai-self-project-backend-monitor
  labels:
    app: ai-self-project-backend
    team: backend
spec:
  selector:
    matchLabels:
      app: ai-self-project-backend
  endpoints:
  - port: http
    path: /api/v1/metrics
    interval: 30s
    scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
    - default
---
# PrometheusRule for alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ai-self-project-backend-alerts
  labels:
    app: ai-self-project-backend
    team: backend
spec:
  groups:
  - name: ai-self-project-backend
    rules:
    - alert: BackendHighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value }} errors per second"

    - alert: BackendHighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High latency detected"
        description: "95th percentile latency is {{ $value }} seconds"

    - alert: BackendDown
      expr: up{app="ai-self-project-backend"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Backend service is down"
        description: "Backend service has been down for more than 1 minute"
---
# Grafana Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-self-project-grafana-dashboard
  labels:
    app: ai-self-project-backend
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "AI Self Project Backend",
        "panels": [
          {
            "title": "Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total[5m])",
                "legendFormat": "{{method}} {{path}}"
              }
            ]
          },
          {
            "title": "Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
                "legendFormat": "{{method}} {{path}}"
              }
            ]
          },
          {
            "title": "Response Time",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
                "legendFormat": "95th percentile"
              }
            ]
          }
        ]
      }
    }
---
# OTLP Collector Service
apiVersion: v1
kind: Service
metadata:
  name: otlp-collector
  labels:
    app: otlp-collector
spec:
  ports:
  - port: 4318
    targetPort: 4318
    protocol: TCP
    name: otlp-http
  - port: 4317
    targetPort: 4317
    protocol: TCP
    name: otlp-grpc
  selector:
    app: otlp-collector
